# 线性回归

## 什么是线性回归
线性回归 是利用函数对自变量（特征值）和因变量（目标值）之间关系进行建模的一种分析方式。  
注意：回归问题数据是连续的。
只有一个自变量的场景叫单变量回归。
多于一个自变量的场景叫多变量回归



## 线性回归有什么作用
线性回归可以用来做回归（即预测）。

## 线性回归方程
<img src="https://github.com/BeGentleman/Machine_Learning/blob/main/img/%E5%A4%9A%E5%8F%98%E9%87%8F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B.png?raw=true">线性回归方程</img>
w是特征权重  
x是特征值  
b是偏置  

## 线性回归模型分类
线性模型：自变量（特征值）x只被一个w所影响。  
非线性模型：自变量（特征值）x被多个因素影响。  

## 线性回归的流程和实现
流程：
step1:先调用sklearn.linear_model 中的LinearRegression
step2:创建数据集
step3:实例化API
step4:使用fit方法进行训练
step5:用estimator.coef_代表系数
step6:用estimator..intercept_代表偏置
step7:estimator.predict([]))来预测，参数都放在一个列表当中（这样就不受到参数个数的限制）

实现：
```python
# 线性回归

# coding:utf-8
from sklearn.linear_model import LinearRegression

x = [
    [80, 86],
    [82, 80],
    [85, 78],
    [90, 90],
    [86, 82],
    [82, 90],
    [78, 80],
    [92, 94]
]
y = [84.2, 80.6, 80.1, 90, 83.2, 87.6, 79.4, 93.4]

# 实例化API
estimator = LinearRegression()

# 使用fit方法进行训练
estimator.fit(x, y)

# 打印对应的系数
print("线性回归的系数是：\n", estimator.coef_)

# 打印偏置
print("偏置", estimator.intercept_)

# 打印预测结果
print("预测的结果：", estimator.predict([[100, 80]]))

```
打印结果：
线性回归的系数是：
 [0.3 0.7]
偏置 -1.4210854715202004e-14
预测的结果： [86.]

Process finished with exit code 0
